\documentclass[12pt]{beamer}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{tikz}
\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}

\input{../header.tex}

%------------------------------------------------
% end of header
%------------------------------------------------

\title{Random Numbers}
\subtitle{STAT 133}
\author{\href{http://www.gastonsanchez.com}{Gaston Sanchez}}
\institute{\href{https://github.com/ucb-stat133/stat133-fall-2016}{\tt \scriptsize \color{foreground} github.com/ucb-stat133/stat133-fall-2016}}
\date{}


\begin{document}
<<setup, include=FALSE>>=
# smaller font size for chunks
opts_chunk$set(size = 'footnotesize')
#thm <- knit_theme$get("bclear")
#knit_theme$set(thm)
options(width=78)
@

{
  \setbeamertemplate{footline}{} % no page number here
  \frame{
    \titlepage
  } 
}

%------------------------------------------------

\begin{frame}
\begin{center}
\Huge{\hilit{Random Numbers in R}}
\end{center}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Generating Random Numbers}

\Large Generation of random numbers is at the heart of many statistical methods

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Use of Random Numbers}

\bb{Some uses of random numbers}
\bbi
  \item Sampling procedures
  \item Simulation studies of stochastic processes
  \item Analytically intractable mathematical expressions
  \item Simulation of a population distribution by resampling from a given sample from that population
  \item More general: Simulation, Monte Carlo, Resampling
\ei
\eb

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Random Samples}

\bi
  \item Many statistical methods rely on random samples:
  \bi
    \item Sampling techniques
    \item Design of experiments
    \item Surveys
  \ei
  \item Hence, we need a source of random numbers
  \item Before computers, statisticians used \textit{tables of random numbers}
  \item Now we use computers to generate ``random'' numbers
  \item The random sampling required in most analyses is usually done by the computer
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Generating Random Numbers}

\bbi
  \item We cannot generate truly random numbers on a computer
  \item Instead, we generate \textbf{pseudo-random} numbers
  \item i.e. numbers that have the appearance of random numbers
  \item they \textit{seem} to be randomly drawn from some known distribution
  \item There are many methods that have been proposed to generate pseudo-random numbers
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Generating Random Numbers}

\Large A very important advantage of using pseudo-random numbers is that, because they are deterministic, they can be reproduced (i.e. repeated)

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Multiple Recursion}

\bbi
  \item Generate a sequence of numbers in a manner that appears to be random
  \item Use a deterministic generator that yields numbers recursively (in a fixed sequence)
  \item The previous $k$ numbers determine the next one
\ei
$$
x_i = f(x_{i-1}, \dots, x_{i-k})
$$

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Simple Congruential Generator}

\bi
  \item Congruential generators were the first reasonable class of pseudo-random number generators
  \item The congruential method uses modular arithmetic to generate ``random'' numbers
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Ingredients}

\bi
  \item An integer $m$
  \item An integer $a$ such that $a < m$
  \item A starting integer $x_0$ (a.k.a. \textit{seed})
\ei

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Simple Congruential Generator}

The first number is obtained as: \\
$
x_{1} = (a \times x_{0}) \text{ mod } m
$

\bigskip
The rest of the pseudorandom numbers are generated as:\\
$
x_{n+1} = (a \times x_{n}) \text{ mod } m
$
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Simple Congruential Generator}

For example if we take $m = 64$, and $a = 3$, then for $x_0 = 17$ we have:

\begin{align*} 
x_1 &= (3 \times 17) \text{ mod } 64 = 51 \\ 
x_2 &= (3 \times 51) \text{ mod } 64 = 25 \\
x_3 &= (3 \times 25) \text{ mod } 64 = 11 \\
x_4 &= (3 \times 11) \text{ mod } 64 = 33 \\ 
x_5 &= (3 \times 33) \text{ mod } 64 = 35 \\
x_6 &= (3 \times 35) \text{ mod } 64 = 41 \\
\vdots \\
\end{align*}

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Congruential algorithm}

<<>>=
a <- 3;  m <- 64;  seed <- 17

x <- numeric(20)

x[1] <- (a * seed) %% m

for (i in 2:20) {
  x[i] <- (a * x[i-1]) %% m
}

x[1:16]; x[17:20]
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Congruential algorithm}
<<>>=
cong <- function(n, a = 69069, m = 2^32, seed = 17) {
  x <- numeric(n)
  x[1] <- (a * seed) %% m
  for (i in 2:n) {
    x[i] <- (a * x[i-1]) %% m
  }
  x
}

y <- cong(20, a = 3, m = 64, seed = 17)
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Congruential algorithm}
<<echo = c(3), fig.width=4, fig.height=4, out.width='.6\\linewidth', out.height='.6\\linewidth', fig.align='center', size='tiny'>>=
n <- length(y)
op <- par(mar = c(4, 4, 1, 1))
plot(y[1:(n-1)], y[2:n], pch = 19,
     xlab = 'current value', ylab = 'next value')
par(op)
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]

\code{cong(n, a = 69069, m = 2\string^32, seed = 17)}
<<echo = FALSE, fig.width=6, fig.height=5, out.width='.8\\linewidth', out.height='.65\\linewidth', fig.align='center'>>=
op <- par(mar = c(4, 4, 1, 1))
y <- cong(500, a = 69069, m = 2^32, seed = 17)
n <- length(y)
plot(y[1:(n-1)], y[2:n], xlab = 'current value', 
     ylab = 'next value', pch = 19, col = '#77777799')
par(op)
@

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Ingredients}

\bi
  \item $m$ is the modulus ($0 < m$)
  \item $a$ is the multiplier ($0 < a < m$)
  \item $x_0$ is the seed ($0 \leq x_0 \leq m$)
\ei

\bigskip
The period length of a Random Generator Number is at most $m$, and for some choices of $a$ much less than that.

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{About the seed}

\bi
  \item You can reproduce your simulation results by controlling the seed
  \item {\hilit \code{set.seed()}} allows to do this
  \item Every time you perform simulation studies indicate the random number generator and the seed that was used
\ei

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{About the seed}

<<>>=
# set the seed
set.seed(69069)

runif(3)  # call the uniform RNG

runif(3)  # call runif() again

# set the seed back to 69069
set.seed(69069)
runif(3)
@

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Simple Congruential Generator}

We can use a congruential algorithm to generate uniform numbers

\bigskip
We'll describe one of the simplest methods for simulating independent uniform random variables on the interaval [0, 1]

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Generating Uniform Numbers}

The generator proceeds as follows
\begin{align*} 
x_1 &= (a x_0) \text{ mod } m \\
u_1 &= x_1 / m \\
\end{align*}

$u_1$ is the first pseudo-random number, taking some value between 0 and 1.

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Ingredients}

The second pseudorandom number is obtained as:
\begin{align*} 
x_2 &= (a x_1) \text{ mod } m \\
u_2 &= x_2 / m \\
\end{align*}

$u_2$ is another pseudorandom number.

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Generating Uniform Numbers}

\bi
  \item If $m$ and $a$ are chosen properly, it is difficult to predict the value $u_2$ given $u_1$
  \item For most practical purposes $u_2$ is approximately independent of $u_1$
\ei

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Simple Congruential Generator}

For example if we take $m = 7$, and $a = 3$, then for $x_0 = 2$ we have:

\begin{align*} 
x_1 &= (3 \times 2) \text{ mod } 7 = 6, \quad u_1 = 0.857 \\ 
x_2 &= (3 \times 6) \text{ mod } 7 = 4, \quad u_2 = 0.571 \\
x_3 &= (3 \times 4) \text{ mod } 7 = 5, \quad u_3 = 0.714 \\
x_4 &= (3 \times 5) \text{ mod } 7 = 1, \quad u_4 = 0.143 \\ 
x_5 &= (3 \times 1) \text{ mod } 7 = 3, \quad u_5 = 0.429 \\
x_6 &= (3 \times 3) \text{ mod } 7 = 2, \quad u_6 = 0.286 \\
\vdots \\
\end{align*}

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Random Numbers in R}

\bb{R uses a pseudo random number generator}
\bi
  \item It starts with a \textbf{seed} and an \textbf{algorithm} (i.e. function)
  \item The seed is plugged into the algorithm and a number is returned
  \item That number is then plugged into the algorithm and the next number is created
  \item The algorithm is such that the produced numbers behave like random numbers
\ei
\eb

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{RNG functions in R}

\begin{center}
 \begin{tabular}{l l}
 \hline
  Function & Description \\
  \hline
  \code{runif()} & Uniform \\  
  \code{rbinom()} & Binomial \\
  \code{rmultinom()} & Multinomial \\  
  \code{rnbinom()} & Negative binomial \\  
  \code{rpois()} & Poisson \\  
  \code{rnorm()} & Normal \\
  \code{rbeta()} & Beta \\  
  \code{rgamma()} & Gamma \\
  \code{rchisq()} & Chi-squared \\
  \code{rcauchy()} & Cauchy \\  
  \hline
 \end{tabular}
\end{center}

See more info: \code{?Distributions}

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Random Number Functions}

{\hilit \code{runif(n, min = 0, max = 1)}} sample from the uniform distribution on the interval (0,1)

\bigskip
The chance the value drawn is:
\bi
  \item between 0 and 1/3 has chance 1/3
  \item between 1/3 and 1/2 has chance 1/6
  \item between 9/10 and 1 has chance 1/10
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Random Number Functions}

{\hilit \code{rnorm(n, mean = 0, sd = 1)}} sample from the normal distribution with center = \code{mean} and spread = \code{sd}

\pause
\bigskip
{\hilit \code{rbinom(n, size, prob)}} sample from the binomial distribution with number of trials = \code{size} and chance of success = \code{prob}

\end{frame}

%------------------------------------------------

\begin{frame}
\begin{center}
\Huge{\hilit{Bootstrapping}}
\end{center}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Let's Generalize}

\bbi
  \item A \textbf{statistic} is just a function of a random sample
  \item Statistics are used as estimators of quantities of interest about the distribution, called \textbf{parameters}
  \item Statistics are random variables
  \item Parameters are NOT random variables
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Let's Generalize}

\bbi
  \item In simple cases, we can study the \textit{sampling distribution} of the statistic analytically
  \item e.g. we can prove under mild conditions that the distribution of the sample proportion is close to normal for large sample sizes
  \item In more complicated cases we can turn to simulation
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Sampling Distributions}

\bbi
  \item In our example $X_1, X_2, \dots, X_n$ are independent observations from the same distribution
  \item The distribution has center (mean value) $\mu$ and spread (standard deviation) $\sigma$
  \item e.g. interest in the distribution of $median(X_1, X_2, \dots, X_n)$
  \item We take many samples of size $n$, and study the behavior of the sample medians
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Some Limitations}

\bi
  \item Consider \textit{t-test} procedures for inference about means
  \item Most classical methods rest on the use of Normal Distributions
  \item However, most real data are not Normal
  \item We cannot use $t$ confidence intervals for strongly skewed data (unless samples are large)
  \item What about inference for a \textit{ratio} of means? (no simple traditional inference)
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Fundamental Reasoning}

\bi
  \item Apply computer power to relax some of the conditions needed in traditional tests
  \item Have tools to do inference in new settings
  \item What would happen if we applied this method many times?
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Bootstrap Idea}

\bi
  \item Statistical inference is based on the sampling distributions of sample statistics
  \item A sampling distribution is based on many random samples from the population
  \item The bootstrap is a way of finding the sampling distribution (approximately)
\ei

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap Samples}

<<>>=
x <- c(3.15, 0, 1.58, 19.65, 0.23, 2.21)
mean(x)
@

\pause
<<>>=
(x1 <- sample(x, size = 6, replace = TRUE))
mean(x1)
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap Samples}

<<>>=
(x2 <- sample(x, size = 6, replace = TRUE))
mean(x2)

(x3 <- sample(x, size = 6, replace = TRUE))
mean(x3)
@

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Procedure for Bootstrapping}

\bbi
  \item Repeatedly sampling \textbf{with replacement} from a random sample
  \item Each bootstrap sample is the same size as the original sample
  \item Calculate the statisc of interest (e.g. mean, median, sd)
  \item Draw hundreds or thousands of samples
  \item Obtain a bootstrap distribution
\ei

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap Samples}

<<>>=
bootstrap <- numeric(1000)

for (b in 1:1000) {
  boot_sample <- sample(x, size = 6, replace = TRUE)
  bootstrap[b] <- mean(boot_sample)
}
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap Distribution}
<<fig.width=4, fig.height=4, out.width='.6\\linewidth', out.height='.6\\linewidth', fig.align='center', size='tiny'>>=
hist(bootstrap, col = 'gray70', las = 1)
@

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{How does Bootstrapping work?}

\bbi
  \item We are not using the resamples as if they were real data
  \item Bootstrap samples is not a substitute to gather more data to improve accuracy
  \item The bootstrap idea is to use the resample statistics to estimate how the sample statistic varies from the studied random sample
  \item The bootstrap distribution approximates the sampling distribution of the statistic
\ei

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Bootstrap samples}

\bb{Computing the bootstrap distribution implies}
\bbi
  \item Calulate the statistic for each sample
  \item The distribution of these resample statistics is the bootstrap distribution
  \item A bootstrap sample is the same size as the original random sample
\ei
\eb

\end{frame}

%------------------------------------------------

\begin{frame}
\begin{center}
\Huge{\hilit{Another Example}}
\end{center}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap resampling}

<<>>=
# Iris Virginica subset (the "population")
virginica <- subset(iris, Species == 'virginica')

# random sample of Petal.Length (size = 5)
set.seed(7359)
rand_sample <- sample(virginica$Petal.Length, size = 5)
rand_sample
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap resampling}

<<>>=
# create 500 bootstrap samples of size 5 with replacement
resamples <- 500
n <- length(rand_sample)

boot_stats <- numeric(resamples)

for (i in 1:resamples) {
  boot_sample <- sample(rand_sample, size = n, replace = TRUE)
  boot_stats[i] <- mean(boot_sample)
}
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap resampling}

<<>>=
# "population" mean 
mean(virginica$Petal.Length)

# bootstrap mean
mean(boot_stats)
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap Distribution}

<<echo = FALSE, fig.width=5, fig.height=5, out.width='.7\\linewidth', out.height='.7\\linewidth', fig.align='center'>>=
hist(boot_stats, col = 'gray80')
@

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\frametitle{Bootstrap standard error}

The bootstrap standard error is just the standard deviation of the bootstrap samples
<<>>=
# descriptive statistics
summary(boot_stats)

# Bootstrap Standard Error
sd(boot_stats)
@

\end{frame}

%------------------------------------------------

\end{document}
